{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a pipeline for comparing the vocabulary of two sets of Tactus emails with eachother by the t-score. The goal is to find tokens which appear more frequently in one set than in the other, and vice versa. This notebook uses much of the preprocessing of the notebook liwc.py in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code block specifies the required libraries. This includes some general Python libraries and some specific libraries developed in our research project. These project-specific libraries can be found in the folder orangehackathon/libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../libs/\")\n",
    "import tactusloaderLIB\n",
    "import OWEmailSorterLIB\n",
    "import markduplicatesLIB\n",
    "import removemarkedtextLIB\n",
    "import LIWCLIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block specifies the location of the therapy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"/home/erikt/projects/e-mental-health/usb/releases/20191217\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Python function was developed for storing the results of the data analysis (SaveResults). In Orange3 the module SaveData can be used for this task. (SaveResults might not be necessary for this notebook tscore.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULTOUTFILE=\"out.csv\"\n",
    "FIELDNAMEDATE = \"date\"\n",
    "FIELDNAMEFROM = \"from\"\n",
    "FIELDNAMEFILE = \"file\"\n",
    "FIELDNAMENBROFMAILS = \"nbr of mails\"\n",
    "CLIENT = \"CLIENT\"\n",
    "COUNSELOR = \"COUNSELOR\"\n",
    "FROMTARGET = CLIENT\n",
    "NBROFMATCHES = \"Number of matches\"\n",
    "\n",
    "# data selection settings\n",
    "PROCESSALLFEATURES = True\n",
    "AVERAGEROWS = False\n",
    "NBROFKEPTROWS = 4\n",
    "MINNBROFMATCHES = 50\n",
    "STUDENTFEATURENAMES = [FIELDNAMEFILE,FIELDNAMEFROM,FIELDNAMENBROFMAILS,\"4 i\",\"7 shehe\",\"8 they\",\"31 posemo\",\\\n",
    "                       \"32 negemo\",\"50 cogproc\",\"51 insight\",\"52 cause\",\"54 tentat\",\\\n",
    "                       \"90 focuspast\",\"91 focuspresent\",\"92 focusfuture\"]\n",
    "\n",
    "def addZero(string):\n",
    "    while len(string) < 2: string = \"0\"+string\n",
    "    return(string)\n",
    "\n",
    "def time2str(timeObj):\n",
    "    date = str(timeObj.tm_year)+\"-\"+addZero(str(timeObj.tm_mon))+\"-\"+addZero(str(timeObj.tm_mday))\n",
    "    time = addZero(str(timeObj.tm_hour))+\":\"+addZero(str(timeObj.tm_min))+\":\"+addZero(str(timeObj.tm_sec))\n",
    "    return(date+\" \"+time)\n",
    "\n",
    "def floatPrecision5(number):\n",
    "    if type(number) != type(0.5): return(number)\n",
    "    else: return(float(\"{0:.5f}\".format(number)))\n",
    "\n",
    "def saveResults(allLiwcResults,fileName=DEFAULTOUTFILE):\n",
    "    if len(allLiwcResults) > 0:\n",
    "        fieldNames = STUDENTFEATURENAMES\n",
    "        if PROCESSALLFEATURES:\n",
    "            fieldNames = [x.name for x in allLiwcResults[0].domain.variables]\n",
    "            fieldNames += [x.name for x in allLiwcResults[0].domain.metas]\n",
    "            fieldNames += [FIELDNAMENBROFMAILS]\n",
    "        outFile = open(fileName,\"w\")\n",
    "        with outFile as csvFile:\n",
    "            csvwriter = csv.DictWriter(csvFile,fieldnames=fieldNames)\n",
    "            csvwriter.writeheader()\n",
    "            for liwcResults in allLiwcResults:\n",
    "                if AVERAGEROWS:\n",
    "                    rowCounter = 0\n",
    "                    row = {}\n",
    "                    for liwcResultsRow in liwcResults:\n",
    "                        liwcResultsRow[FIELDNAMEFILE] = re.sub(\"-an.xml.gz\",\"\",str(liwcResultsRow[FIELDNAMEFILE]))\n",
    "                        if liwcResultsRow[FIELDNAMEFROM] == FROMTARGET:\n",
    "                            rowCounter += 1\n",
    "                            nbrOfMatches = 0\n",
    "                            if NBROFMATCHES in liwcResultsRow: nbrOfMatches = int(liwcResultsRow[NBROFMATCHES])\n",
    "                            if (NBROFKEPTROWS == 0 or rowCounter <= NBROFKEPTROWS) and \\\n",
    "                               (MINNBROFMATCHES == 0 or nbrOfMatches >= MINNBROFMATCHES):\n",
    "                                for fieldName in fieldNames:\n",
    "                                    if fieldName == FIELDNAMEDATE:\n",
    "                                        row[fieldName] = time2str(time.localtime(liwcResultsRow[fieldName].value))\n",
    "                                    elif not re.match(\"^\\d+\\s\",fieldName):\n",
    "                                        try: row[fieldName] = liwcResultsRow[fieldName].value\n",
    "                                        except: pass\n",
    "                                    elif fieldName in row: \n",
    "                                        row[fieldName] += floatPrecision5(liwcResultsRow[fieldName].value)\n",
    "                                    else: \n",
    "                                        row[fieldName] = floatPrecision5(liwcResultsRow[fieldName].value)\n",
    "                    if len(row) > 0:\n",
    "                        for fieldName in row:\n",
    "                            if re.match(\"^\\d+\\s\",fieldName) and rowCounter > 0: \n",
    "                                row[fieldName] = floatPrecision5(row[fieldName]/min(rowCounter,NBROFKEPTROWS))\n",
    "                        row[FIELDNAMENBROFMAILS] = rowCounter\n",
    "                        csvwriter.writerow(row)\n",
    "                else:\n",
    "                    rowCounter = 0\n",
    "                    row = {}\n",
    "                    for liwcResultsRow in liwcResults:\n",
    "                        liwcResultsRow[FIELDNAMEFILE] = re.sub(\"-an.xml.gz\",\"\",str(liwcResultsRow[FIELDNAMEFILE]))\n",
    "                        if liwcResultsRow[FIELDNAMEFROM] == FROMTARGET:\n",
    "                            rowCounter += 1\n",
    "                            nbrOfMatches = liwcResultsRow[NBROFMATCHES]\n",
    "                            if (NBROFKEPTROWS == 0 or rowCounter <= NBROFKEPTROWS) and \\\n",
    "                               (MINNBROFMATCHES == 0 or nbrOfMatches >= MINNBROFMATCHES):\n",
    "                                for fieldName in fieldNames:\n",
    "                                    if fieldName == FIELDNAMEDATE:\n",
    "                                        row[fieldName] = time2str(time.localtime(liwcResultsRow[fieldName].value))\n",
    "                                    elif not re.match(\"^\\d+\\s\",fieldName):\n",
    "                                        try: row[fieldName] = liwcResultsRow[fieldName].value\n",
    "                                        except: pass\n",
    "                                    else: \n",
    "                                        row[fieldName] = floatPrecision5(liwcResultsRow[fieldName].value)\n",
    "                                if len(row) > 0: csvwriter.writerow(row)\n",
    "        outFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will comparethe texts in emails from clients that finished the treatment versus clients that dropped out. Thus we need the metadata which specifies the results of the therapy for each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "DIRDROPOUT = \"/home/erikt/projects/e-mental-health/usb/releases/20200218\"\n",
    "FILEDROPOUT = \"dropoutAUKE.csv.gz\"\n",
    "DELIMITER = \",\"\n",
    "FIELDNAMEDROPOUT = \"dropout\"\n",
    "FIELDNAMETEXT = \"text\"\n",
    "FIELDNAMECLIENTID = \"clientID\"\n",
    "\n",
    "dropout = {}\n",
    "inFile = gzip.open(DIRDROPOUT+\"/\"+FILEDROPOUT,\"rt\",encoding=\"utf-8\")\n",
    "csvreader = csv.DictReader(inFile,delimiter=DELIMITER)\n",
    "for row in csvreader: dropout[row[FIELDNAMECLIENTID]] = row[FIELDNAMEDROPOUT]\n",
    "inFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally there is a loop which loads each available therapy file, runs the Orange3 pipeline. The Orange3 pipeline contains these parts:\n",
    "\n",
    "1. tactusloader: determine file name and read its contents\n",
    "2. sortMails: sort the mails from the file chronologically\n",
    "3. markduplicates: mark the parts of the mail text included from an earlier mail\n",
    "4. removemarkedtext: remove the marked text from the mail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXMAILS = 4\n",
    "\n",
    "allLiwcResults = []\n",
    "mailTexts = [\"\",\"\",\"\"]\n",
    "for patientId in list(range(1,1988)):\n",
    "    fileName = tactusloaderLIB.makeFileName(str(patientId))\n",
    "    fileNameId = re.sub(\"-an.xml$\",\"\",fileName)\n",
    "    if fileNameId in dropout and (dropout[fileNameId] == \"1\" or dropout[fileNameId] == \"2\"):\n",
    "        mailText = \"\"\n",
    "        try:\n",
    "            mails = tactusloaderLIB.processFile(DIRECTORY,fileName+\".gz\")\n",
    "            #print(fileName,len(mails),len(mails[0]),len(mails[1]),mails[0][0])\n",
    "            if len(mails) > 0:\n",
    "                sortedMails = OWEmailSorterLIB.filterEmails(mails[0],filter_asc=True)\n",
    "                markedMails = markduplicatesLIB.processCorpus(sortedMails)\n",
    "                strippedMails = removemarkedtextLIB.processCorpus(markedMails)\n",
    "                #print(fileName,dropout[fileNameId],len(strippedMails),strippedMails[0])\n",
    "                mailCounter = 0\n",
    "                for strippedMail in strippedMails:\n",
    "                    if strippedMail[FIELDNAMEFROM] == CLIENT and mailCounter < MAXMAILS:\n",
    "                        mailText += str(strippedMail[FIELDNAMETEXT])\n",
    "                        mailCounter += 1\n",
    "                #print(mailText)\n",
    "                #break\n",
    "        except:\n",
    "            print(\"problem processing file\",fileName)\n",
    "            continue\n",
    "        mailTexts[int(dropout[fileNameId])] += mailText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(mailTexts)): print(len(mailTexts[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the text to the data format of the t-score script: /home/erikt/projects/newsgac/fasttext-runs/tscore.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFTOKENS = \"totalFreq\"\n",
    "NBROFTYPES = \"nbrOfWords\"\n",
    "WORDFREQS = \"wordFreqs\"\n",
    "\n",
    "def makeTscoreData(text):\n",
    "    data = { NBROFTOKENS:0, NBROFTYPES:0, WORDFREQS:{} }\n",
    "    for token in text.split():\n",
    "        data[NBROFTOKENS] += 1\n",
    "        if token in data[WORDFREQS]: \n",
    "            data[WORDFREQS][token] += 1\n",
    "        else:\n",
    "            data[WORDFREQS][token] = 1\n",
    "            data[NBROFTYPES] += 1\n",
    "    return(data)\n",
    "\n",
    "tscoreData1 = makeTscoreData(mailTexts[1])\n",
    "tscoreData2 = makeTscoreData(mailTexts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/erikt/projects/newsgac/fasttext-runs\")\n",
    "import tscore\n",
    "import operator\n",
    "\n",
    "outFile = open(\"out.csv\",\"w\")\n",
    "csvwriter = csv.DictWriter(outFile,[\"token\",\"tscore\",\"freqDropouts\",\"freqFinishers\"])\n",
    "csvwriter.writeheader()\n",
    "tscores = tscore.computeTscore(tscoreData1,tscoreData2)\n",
    "for tuple in sorted(tscores.items(), key=operator.itemgetter(1)):\n",
    "    (token,tscore) = tuple\n",
    "    if token in tscoreData1[WORDFREQS]: frequency1 = tscoreData1[WORDFREQS][token]\n",
    "    else: frequency1 = 0\n",
    "    if token in tscoreData2[WORDFREQS]: frequency2 = tscoreData2[WORDFREQS][token]\n",
    "    else: frequency2 = 0\n",
    "    csvwriter.writerow({\"token\":token,\"tscore\":tscore,\"freqDropouts\":frequency1,\"freqFinishers\":frequency2})\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
