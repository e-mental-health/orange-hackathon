{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a pipeline for comparing the vocabulary of two sets of Tactus emails with eachother by the t-score. The goal is to find tokens which appear more frequently in one set than in the other, and vice versa. This notebook uses much of the preprocessing of the notebook liwc.py in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code block specifies the required libraries. This includes some general Python libraries and some specific libraries developed in our research project. These project-specific libraries can be found in the folder orangehackathon/libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../libs/\")\n",
    "import tactusloaderLIB\n",
    "import OWEmailSorterLIB\n",
    "import markduplicatesLIB\n",
    "import removemarkedtextLIB\n",
    "import LIWCLIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block specifies the location of the therapy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"/home/erikt/projects/e-mental-health/usb/releases/20191217\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Python function was developed for storing the results of the data analysis (SaveResults). In Orange3 the module SaveData can be used for this task. (SaveResults might not be necessary for this notebook tscore.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will comparethe texts in emails from clients that finished the treatment versus clients that dropped out. Thus we need the metadata which specifies the results of the therapy for each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "DIRDROPOUT = \"/home/erikt/projects/e-mental-health/usb/releases/20200305/\"\n",
    "FILEDROPOUT = \"selected.csv.gz\"\n",
    "DELIMITER = \",\"\n",
    "FIELDNAMEDROPOUT = \"dropout\"\n",
    "FIELDNAMETEXT = \"text\"\n",
    "FIELDNAMEFILE = \"file\"\n",
    "FIELDNAMEFROM = \"from\"\n",
    "CLIENT = \"CLIENT\"\n",
    "NBROFCLIENTS = 791\n",
    "\n",
    "dropout = {}\n",
    "inFile = gzip.open(DIRDROPOUT+FILEDROPOUT,\"rt\",encoding=\"utf-8\")\n",
    "csvreader = csv.DictReader(inFile,delimiter=DELIMITER)\n",
    "for row in csvreader: dropout[row[FIELDNAMEFILE]] = row[FIELDNAMEDROPOUT]\n",
    "inFile.close()\n",
    "\n",
    "len([x for x in dropout if dropout[x] != \"?\"]) == NBROFCLIENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally there is a loop which loads each available therapy file, runs the Orange3 pipeline. The Orange3 pipeline contains these parts:\n",
    "\n",
    "1. tactusloader: determine file name and read its contents\n",
    "2. sortMails: sort the mails from the file chronologically\n",
    "3. markduplicates: mark the parts of the mail text included from an earlier mail\n",
    "4. removemarkedtext: remove the marked text from the mail\n",
    "\n",
    "The file loading takes some time. The program counts from 0 to 1987 in steps of 100 to indicate its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0..1987): 0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 1987\n"
     ]
    }
   ],
   "source": [
    "MAXMAILS = 4\n",
    "MAXCLIENT = 1987\n",
    "\n",
    "allLiwcResults = []\n",
    "mailTexts = [{},{},{}]\n",
    "print(\"(0..\"+str(MAXCLIENT)+\"):\",0,end=\" \")\n",
    "for patientId in list(range(1,MAXCLIENT+1)):\n",
    "    if patientId % 100 == 0: print(patientId,end=\" \")\n",
    "    fileName = tactusloaderLIB.makeFileName(str(patientId))\n",
    "    fileNameId = re.sub(\"-an.xml$\",\"\",fileName)\n",
    "    if fileNameId in dropout and (dropout[fileNameId] == \"1\" or dropout[fileNameId] == \"2\"):\n",
    "        mailText = \"\"\n",
    "        try:\n",
    "            mails = tactusloaderLIB.processFile(DIRECTORY,fileName+\".gz\")\n",
    "            if len(mails) > 0:\n",
    "                sortedMails = OWEmailSorterLIB.filterEmails(mails[0],filter_asc=True)\n",
    "                markedMails = markduplicatesLIB.processCorpus(sortedMails)\n",
    "                strippedMails = removemarkedtextLIB.processCorpus(markedMails)\n",
    "                mailCounter = 0\n",
    "                for strippedMail in strippedMails:\n",
    "                    if strippedMail[FIELDNAMEFROM] == CLIENT and mailCounter < MAXMAILS:\n",
    "                        mailText += str(strippedMail[FIELDNAMETEXT])\n",
    "                        mailCounter += 1\n",
    "        except:\n",
    "            print(\"problem processing file\",fileName)\n",
    "            continue\n",
    "        mailTexts[int(dropout[fileNameId])][fileNameId] = mailText\n",
    "print(patientId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROPOUTID = 1\n",
    "FINISHERID = 2\n",
    "NBROFDROPOUTS = 437\n",
    "NBROFFINISHERS = 354\n",
    "\n",
    "len(mailTexts[DROPOUTID]) == NBROFDROPOUTS and len(mailTexts[FINISHERID]) == NBROFFINISHERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, convert the text to the data format of the t-score script: /home/erikt/projects/newsgac/fasttext-runs/tscore.py . There are two ways for computing the t-scores: count every separate word used by a client or count each word used by a client only once. The texts can be prepared for the second type of counts with the function uniqueTextArray() which removes all duplicate words from the texts (case-sensitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFTOKENS = \"totalFreq\"\n",
    "NBROFTYPES = \"nbrOfWords\"\n",
    "WORDFREQS = \"wordFreqs\"\n",
    "MAXCOUNT = \"maxCount\"\n",
    "\n",
    "def makeTscoreData(textArray):\n",
    "    data = { NBROFTOKENS:0, NBROFTYPES:0, MAXCOUNT:len(textArray), WORDFREQS:{} }\n",
    "    for text in textArray:\n",
    "        for token in text.split():\n",
    "            data[NBROFTOKENS] += 1\n",
    "            if token in data[WORDFREQS]: \n",
    "                data[WORDFREQS][token] += 1\n",
    "            else:\n",
    "                data[WORDFREQS][token] = 1\n",
    "                data[NBROFTYPES] += 1\n",
    "    return(data)\n",
    "\n",
    "def uniqueText(text):\n",
    "    seen = {}\n",
    "    for word in text.split():\n",
    "        if not word in seen: seen[word] = True\n",
    "    return(\" \".join(list(seen.keys())))\n",
    "\n",
    "def uniqueTextArray(textDictIn):\n",
    "    textArrayOut = []\n",
    "    for fileNameId in textDictIn:\n",
    "        textArrayOut.append(uniqueText(textDictIn[fileNameId]))\n",
    "    return(textArrayOut)\n",
    "\n",
    "def normalizeMaxCount(tscoreData,fraction):\n",
    "    tscoreData[MAXCOUNT] = round(tscoreData[MAXCOUNT]*fraction,1)\n",
    "    for word in tscoreData[\"wordFreqs\"]:\n",
    "        tscoreData[\"wordFreqs\"][word] = round(tscoreData[\"wordFreqs\"][word]*fraction,1)\n",
    "    return(tscoreData)\n",
    "    \n",
    "tscoreData1 = makeTscoreData(uniqueTextArray(mailTexts[1]))\n",
    "tscoreData2 = makeTscoreData(uniqueTextArray(mailTexts[2]))\n",
    "# tscoreData2 = normalizeMaxCount(tscoreData2,tscoreData1[\"maxCount\"]/tscoreData2[\"maxCount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 mvg 2.6069437444795414 16 3\n",
      "2 hapje 2.5902771425883144 8 0\n",
      "3 late 2.3803980606815736 39 16\n",
      "4 schoonouders 2.3313558655467217 12 2\n",
      "5 armen 2.2281041549259886 9 1\n",
      "6 externe 2.1831297072252833 6 0\n",
      "7 Vanmiddag 2.1831297072252833 6 0\n",
      "8 opgestoken 2.1831297072252833 6 0\n",
      "9 oppas 2.1831297072252833 6 0\n",
      "10 an 2.0246074095722575 8 1\n",
      "11 Mvg 2.0246074095722575 8 1\n",
      "12 groenten 1.960228533856725 10 2\n",
      "13 inhoudt 1.960228533856725 10 2\n",
      "14 langzamer 1.9513725557372972 5 0\n",
      "15 bios 1.9513725557372972 5 0\n",
      "16 uitwerking 1.9513725557372972 5 0\n",
      "17 verkouden 1.9513725557372972 5 0\n",
      "18 T 1.9513725557372972 5 0\n",
      "19 baalt 1.9513725557372972 5 0\n",
      "20 ondervinden 1.9513725557372972 5 0\n",
      "29871 sportschool -4.093160180780137 9 33\n",
      "29872 leeg -4.098771481280528 25 55\n",
      "29873 Een -4.101059978239603 103 143\n",
      "29874 lijkt -4.143443243577608 68 106\n",
      "29875 voordelen -4.14647358033523 136 178\n",
      "29876 hoofd -4.18232537098759 63 101\n",
      "29877 emotionele -4.202963434984855 28 60\n",
      "29878 groep -4.209407611770016 18 47\n",
      "29879 Dank -4.215909306760129 46 82\n",
      "29880 pijn -4.24257336063911 64 103\n",
      "29881 zeggen -4.288635576511674 118 162\n",
      "29882 bespreken -4.361528784773401 8 34\n",
      "29883 toch -4.36917264611581 207 254\n",
      "29884 gevoel -4.389052908745457 150 197\n",
      "29885 uur -4.390321253604521 149 196\n",
      "29886 voelde -4.516511327947278 71 115\n",
      "29887 hem -4.522499569798921 114 162\n",
      "29888 Wat -4.533226467080627 111 159\n",
      "29889 glas -4.620015788749803 74 120\n",
      "29890 gedachten -4.830482064818652 40 83\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/home/erikt/projects/newsgac/fasttext-runs\")\n",
    "import tscore\n",
    "import operator\n",
    "\n",
    "TOPPOS = 20\n",
    "\n",
    "def computeTscores(tscoreData1,tscoreData2):\n",
    "    outFile = open(\"out.csv\",\"w\")\n",
    "    csvwriter = csv.DictWriter(outFile,[\"position\",\"token\",\"tscore\",\"freqDropouts\",\"freqFinishers\"])\n",
    "    csvwriter.writeheader()\n",
    "    tscores = tscore.computeTscoreUniqueWords(tscoreData1,tscoreData2)\n",
    "    position = 0\n",
    "    for tuple in sorted(tscores.items(), key=operator.itemgetter(1),reverse=True):\n",
    "        position += 1\n",
    "        (token,tokenTscore) = tuple\n",
    "        if token in tscoreData1[WORDFREQS]: frequency1 = tscoreData1[WORDFREQS][token]\n",
    "        else: frequency1 = 0\n",
    "        if token in tscoreData2[WORDFREQS]: frequency2 = tscoreData2[WORDFREQS][token]\n",
    "        else: frequency2 = 0\n",
    "        csvwriter.writerow({\"position\":position,\"token\":token,\"tscore\":tokenTscore,\\\n",
    "                            \"freqDropouts\":frequency1,\"freqFinishers\":frequency2})\n",
    "        if position <= TOPPOS or position+TOPPOS > len(tscores): \n",
    "            print(position,token,tokenTscore,frequency1,frequency2)\n",
    "    outFile.close()\n",
    "    \n",
    "computeTscores(tscoreData1,tscoreData2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top of the list contains words that are more frequently used by the dropouts among the clients (category 1) than by the finishers (category 2), as can be seen from the counts in last two columns, for example for *mvg*: 16 > 3. \n",
    "\n",
    "Originally, this observation was not true for the top of the list, which contained mainly frequent words. Why was this the case? The problem proved to be the computation of the t-score. We removed the concepts of text lengths and vocabulary length used in the original definition of the t-score (Church, Gale, Hanks & Hindle, 1991) and replaced this with maximum attainable value: the number of clients per group, since the words were only counted once for each client. We kept using add-0.5 smoothing and adjusted the maximum attanable value with 0.5 as well to account for this. The top of the list improved a lot, with *mvg*, *hapje* and *late* occuring at the top of the list. The bottom of the list, words typically used by finishers did not contain many clear cases like *PS* on place -89 (0 vs 13) but no errors could be found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: male vs female words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "sys.path.append('/home/erikt/projects/e-mental-health/data-processing')\n",
    "import tactus2table\n",
    "\n",
    "DIRECTORY = \"/home/erikt/projects/e-mental-health/usb/tmp/20190917/\"\n",
    "FILENAMEPREFIX = \"^AdB\"\n",
    "TITLE = \"0-title\"\n",
    "FIELDNAMEINTAKE = \"Intake\"\n",
    "FIELDNAMEID = \"0-id\"\n",
    "FIELDNAMEGENDER = \"geslacht\"\n",
    "GZEXTENSION = \".gz\"\n",
    "XMLEXTENSION = \".xml\"\n",
    "MALE = \"man\"\n",
    "FEMALE = \"vrouw\"\n",
    "\n",
    "def shortenFileName(fileName):\n",
    "    return(re.sub(XMLEXTENSION,\"\",re.sub(GZEXTENSION,\"\",fileName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = {}\n",
    "for inFileName in os.listdir(DIRECTORY):\n",
    "    if re.search(FILENAMEPREFIX,inFileName):\n",
    "        root = tactus2table.readRootFromFile(DIRECTORY+\"/\"+inFileName)\n",
    "        questionnaires = tactus2table.getQuestionnaires(root,inFileName)\n",
    "        for questionnaire in questionnaires: \n",
    "            if questionnaire[TITLE] == INTAKE:\n",
    "                for fieldName in questionnaire:\n",
    "                    if re.search(FIELDNAMEGENDER,fieldName):\n",
    "                        genders[shortenFileName(questionnaire[FIELDNAMEID])] = questionnaire[fieldName].lower()\n",
    "                        break\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderKeys = list(np.unique(np.array([genders[key] for key in genders])))\n",
    "genderMailTexts = {}\n",
    "for key in genderKeys: genderMailTexts[key] = {}\n",
    "for result in range(0,len(mailTexts)):\n",
    "    for fileId in mailTexts[result].keys():\n",
    "        genderMailTexts[genders[fileId]][fileId] = mailTexts[result][fileId]\n",
    "[(key,len(genderMailTexts[key])) for key in genderKeys]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscoreData1 = makeTscoreData(uniqueTextArray(genderMailTexts[MALE]))\n",
    "tscoreData2 = makeTscoreData(uniqueTextArray(genderMailTexts[FEMALE]))\n",
    "computeTscores(tscoreData1,tscoreData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-orange",
   "language": "python",
   "name": "python-orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
