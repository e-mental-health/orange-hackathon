{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a pipeline for comparing the vocabulary of two sets of Tactus emails with eachother by the t-score. The goal is to find tokens which appear more frequently in one set than in the other, and vice versa. This notebook uses much of the preprocessing of the notebook liwc.py in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code block specifies the required libraries. This includes some general Python libraries and some specific libraries developed in our research project. These project-specific libraries can be found in the folder orangehackathon/libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append(\"../libs/\")\n",
    "import tactusloaderLIB\n",
    "import OWEmailSorterLIB\n",
    "import markduplicatesLIB\n",
    "import removemarkedtextLIB\n",
    "import LIWCLIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block specifies the location of the therapy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"/home/erikt/projects/e-mental-health/usb/releases/20200320\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The therapy files are read with the Orange3 pipeline. The Orange3 pipeline contains these parts:\n",
    "\n",
    "1. tactusloader: determine file name and read its contents\n",
    "2. sortMails: sort the mails from the file chronologically\n",
    "3. markduplicates: mark the parts of the mail text included from an earlier mail\n",
    "4. removemarkedtext: remove the marked text from the mail\n",
    "5. LIWC: analyse the text with LIWC\n",
    "\n",
    "The file loading takes several minutes. The program counts from 1 to the number of files to indicate its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXCLIENT = 1987\n",
    "\n",
    "def readTactusData(maxClient):\n",
    "    allLiwcResults = {}\n",
    "    allMails = {}\n",
    "    emptyFiles = []\n",
    "    problemFiles = []\n",
    "    for patientId in range(1,maxClient+1):\n",
    "        clear_output(wait=True)\n",
    "        print(\"processing:\",patientId)\n",
    "        fileName = tactusloaderLIB.makeFileName(str(patientId))\n",
    "        fileNameId = re.sub(\"-an.xml$\",\"\",fileName)\n",
    "        try:\n",
    "            mails = tactusloaderLIB.processFile(DIRECTORY,fileName+\".gz\")\n",
    "            if len(mails[0]) > 0:\n",
    "                sortedMails = OWEmailSorterLIB.filterEmails(mails[0],filter_asc=True)\n",
    "                markedMails = markduplicatesLIB.processCorpus(sortedMails)\n",
    "                strippedMails = removemarkedtextLIB.processCorpus(markedMails)\n",
    "                liwcResults = LIWCLIB.processCorpus(strippedMails)\n",
    "                allLiwcResults[fileNameId] = liwcResults\n",
    "                allMails[fileNameId] = strippedMails\n",
    "            else: emptyFiles.append(fileName)\n",
    "        except:\n",
    "            problemFiles.append(fileName)\n",
    "            continue\n",
    "    if len(emptyFiles) > 0:\n",
    "        print(\"Found empty or nonexistant files:\",emptyFiles)\n",
    "    if len(problemFiles) > 0:\n",
    "        print(\"There were problems processing these files:\",problemFiles)\n",
    "    return(allLiwcResults,allMails)\n",
    "\n",
    "allLiwcResults,allMails = readTactusData(MAXCLIENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allMails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will comparethe texts in emails from clients that finished the treatment versus clients that dropped out. Thus we need the metadata which specifies the results of the therapy for each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "DIRDROPOUT = \"/home/erikt/projects/e-mental-health/usb/releases/20200305/\"\n",
    "FILEDROPOUT = \"selected.csv.gz\"\n",
    "DELIMITER = \",\"\n",
    "FIELDNAMEDROPOUT = \"dropout\"\n",
    "FIELDNAMETEXT = \"text\"\n",
    "FIELDNAMEFILE = \"file\"\n",
    "FIELDNAMEFROM = \"from\"\n",
    "CLIENT = \"CLIENT\"\n",
    "COUNSELOR = \"COUNSELOR\"\n",
    "NBROFCLIENTS = 791\n",
    "CODEDROPOUT = \"1\"\n",
    "CODEFINISHER = \"2\"\n",
    "\n",
    "dropout = {}\n",
    "inFile = gzip.open(DIRDROPOUT+FILEDROPOUT,\"rt\",encoding=\"utf-8\")\n",
    "csvreader = csv.DictReader(inFile,delimiter=DELIMITER)\n",
    "for row in csvreader: dropout[row[FIELDNAMEFILE]] = row[FIELDNAMEDROPOUT]\n",
    "inFile.close()\n",
    "\n",
    "len([x for x in dropout if dropout[x] != \"?\"]) == NBROFCLIENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare collections of texts with the t-score. First we will compute the t-scores of various text collections with a function `makeTscoreData`. After this we can compare these t-scores with the function `compareTscoreData`. We rely on the t-score script `/home/erikt/projects/newsgac/fasttext-runs/tscore.py` for making the comparisons. \n",
    "\n",
    "There are two ways for computing the t-scores: count every separate word used by a client or count each word used by a client only once. The texts can be prepared for the second type of counts with the function `removeDuplicateTokensTextArray` which removes all duplicate words from the texts (case-sensitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFTOKENS = \"totalFreq\"\n",
    "NBROFTYPES = \"nbrOfWords\"\n",
    "WORDFREQS = \"wordFreqs\"\n",
    "NBROFGROUPS = \"nbrOfGroups\"\n",
    "\n",
    "def normalizeMaxCount(tscoreData,fraction):\n",
    "    tscoreData[MAXCOUNT] = round(tscoreData[MAXCOUNT]*fraction,1)\n",
    "    for word in tscoreData[\"wordFreqs\"]:\n",
    "        tscoreData[\"wordFreqs\"][word] = round(tscoreData[\"wordFreqs\"][word]*fraction,1)\n",
    "    return(tscoreData)\n",
    "\n",
    "def removeEmptyMails(textArrayIn):    \n",
    "    return([text for text in textArrayIn if text != \"\"])\n",
    "\n",
    "def removeDuplicateTokensText(text):\n",
    "    seen = {}\n",
    "    for word in text.split():\n",
    "        if not word in seen: seen[word] = True\n",
    "    return(\" \".join(list(seen.keys())))\n",
    "\n",
    "def removeDuplicateTokensTextArray(textArrayIn):\n",
    "    textArrayOut = []\n",
    "    for text in textArrayIn:\n",
    "        textArrayOut.append(removeDuplicateTokens(text))\n",
    "    return(textArrayOut)\n",
    "\n",
    "def makeTscoreData(textArray):\n",
    "    data = { NBROFTOKENS:0, NBROFTYPES:0, NBROFGROUPS:len(textArray), WORDFREQS:{} }\n",
    "    for text in textArray:\n",
    "        for token in text.split():\n",
    "            data[NBROFTOKENS] += 1\n",
    "            if token in data[WORDFREQS]: \n",
    "                data[WORDFREQS][token] += 1\n",
    "            else:\n",
    "                data[WORDFREQS][token] = 1\n",
    "                data[NBROFTYPES] += 1\n",
    "    return(data)\n",
    "\n",
    "def makeTscoreDataBigrams(textArray):\n",
    "    data = { NBROFTOKENS:0, NBROFTYPES:0, NBROFGROUPS:len(textArray), WORDFREQS:{} }\n",
    "    for text in textArray:\n",
    "        tokens = text.split()\n",
    "        for i in range(1,len(tokens)):\n",
    "            bigram = tokens[i-1]+\" \"+tokens[i]\n",
    "            data[NBROFTOKENS] += 1\n",
    "            if bigram in data[WORDFREQS]: \n",
    "                data[WORDFREQS][bigram] += 1\n",
    "            else:\n",
    "                data[WORDFREQS][bigram] = 1\n",
    "                data[NBROFTYPES] += 1\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/erikt/projects/newsgac/fasttext-runs\")\n",
    "import tscore\n",
    "import operator\n",
    "from termcolor import colored\n",
    "# alternative: from IPython.display import Markdown; display(Markdown(\"htmlcode\"))\n",
    "\n",
    "HIGHLIGHTCOLOR = \"blue\"\n",
    "ADDEDSPACES = 9\n",
    "MAXSTRING = 20\n",
    "\n",
    "def fillAddedSpaces(tokenLen):\n",
    "    addedSpaces = \"\"\n",
    "    i = 0\n",
    "    while i < ADDEDSPACES and tokenLen+i-ADDEDSPACES < MAXSTRING:\n",
    "        addedSpaces += \" \"\n",
    "        i += 1\n",
    "    return(addedSpaces)\n",
    "\n",
    "def compareTscoreData(tscoreData1,tscoreData1reference,tscoreData2,tscoreData2reference,nbrOfShow,coloredWords=[]):\n",
    "    outFile = open(\"out.csv\",\"w\")\n",
    "    csvwriter = csv.DictWriter(outFile,[\"position\",\"token\",\"tscore\",\"freqDropouts\",\"freqFinishers\"])\n",
    "    csvwriter.writeheader()\n",
    "    tscores1 = tscore.computeTscore(tscoreData1,tscoreData1reference)\n",
    "    tscores2 = tscore.computeTscore(tscoreData2,tscoreData2reference)\n",
    "    tscores1sorted = sorted(tscores1.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    tscores2sorted = sorted(tscores2.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    combined = [ tscores1sorted[i]+tscores2sorted[i] for i in range(min(len(tscores1sorted),len(tscores2sorted))) ]\n",
    "    position = 0\n",
    "    for tuple in combined:\n",
    "        position += 1\n",
    "        (token1,token1Tscore,token2,token2Tscore) = tuple\n",
    "        if token1 in tscoreData1[WORDFREQS]: frequency11 = tscoreData1[WORDFREQS][token1]\n",
    "        else: frequency11 = 0\n",
    "        if token1 in tscoreData1reference[WORDFREQS]: frequency1r = tscoreData1reference[WORDFREQS][token1]\n",
    "        else: frequency1r = 0\n",
    "        if token2 in tscoreData2[WORDFREQS]: frequency22 = tscoreData2[WORDFREQS][token2]\n",
    "        else: frequency22 = 0\n",
    "        if token2 in tscoreData2reference[WORDFREQS]: frequency2r = tscoreData2reference[WORDFREQS][token2]\n",
    "        else: frequency2r = 0\n",
    "        csvwriter.writerow({\"position\":position,\"token\":token1,\"tscore\":token1Tscore,\\\n",
    "                            \"freqDropouts\":frequency11,\"freqFinishers\":frequency1r})\n",
    "        if position <= nbrOfShow:\n",
    "            token1AddedSpaces = \"\"\n",
    "            if token1 in coloredWords: \n",
    "                token1 = colored(token1,HIGHLIGHTCOLOR)\n",
    "                token1AddedSpaces = fillAddedSpaces(len(token1))\n",
    "            if token2 in coloredWords: token2 = colored(token2,HIGHLIGHTCOLOR)\n",
    "            print(\"{0:6d}. {2:5.1f} {3:7d} {4:7d} {1:<20s}{5:s} {0:6d}. {7:5.1f} {8:7d} {9:7d} {6:<20s}\".\\\n",
    "                  format(position,token1,round(token1Tscore,1),frequency11,frequency1r,token1AddedSpaces, \\\n",
    "                                  token2,round(token2Tscore,1),frequency22,frequency2r))\n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose the text collections that we want to compare. Here are the choices:\n",
    "\n",
    "1. all mails of all clients\n",
    "2. all mails of all counselors\n",
    "3. the final mail written by a counselor to a client that dropped out\n",
    "4. the final mail written to a counselor to a client that finished the therapy\n",
    "5. the first four mails of a client that dropped out\n",
    "6. the first four mails of a client that finished the therapy\n",
    "7. the long mails among the first four mails of a client that dropped out\n",
    "8. the long mails among the first four mails of a client that finished the therapy\n",
    "9. all mails of all clients that dropped out\n",
    "10. all mails of all clients that finished the therapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientWithMails = [ clientId for clientId in allMails.keys() if len(allMails[clientId]) > 0 ][0]\n",
    "textFieldId = LIWCLIB.getFieldId(allMails[clientWithMails][0],FIELDNAMETEXT) \n",
    "\n",
    "def wordCount(text): return(len(text.split()))\n",
    "\n",
    "def selectMailsFrom(mails,sender):\n",
    "    return([ mail for mail in mails if mail[FIELDNAMEFROM] == sender ])\n",
    "\n",
    "def selectAllMailTextFrom(mails,sender):\n",
    "    return(\" \".join([ mail.metas[textFieldId] for mail in selectMailsFrom(mails,sender) ]))\n",
    "\n",
    "def selectLastNMailTextsFrom(mails,sender,n):\n",
    "    return(\" \".join([ mail.metas[textFieldId] for mail in selectMailsFrom(mails,sender) ][-n:]))\n",
    "\n",
    "def selectFirstNMailTextsFrom(mails,sender,n,cutoff=0):\n",
    "    firstNtexts = [ mail.metas[textFieldId] for mail in selectMailsFrom(mails,sender) ][0:n]\n",
    "    return(\" \".join([ text for text in firstNtexts if wordCount(text) >= cutoff ]))\n",
    "\n",
    "allMailsClients = [ selectAllMailTextFrom(allMails[thisId],CLIENT) for thisId in allMails ]\n",
    "allMailsCounselors = [ selectAllMailTextFrom(allMails[thisId],COUNSELOR) for thisId in allMails ]\n",
    "\n",
    "NBROFSELECTED = 1\n",
    "lastCounselorMails = { thisId:selectLastNMailTextsFrom(allMails[thisId],COUNSELOR,NBROFSELECTED) for thisId in allMails }\n",
    "lastCounselorMailsDropout = [ lastCounselorMails[clientId] for clientId in dropout if dropout[clientId] == CODEDROPOUT ]\n",
    "lastCounselorMailsFinisher = [ lastCounselorMails[clientId] for clientId in dropout if dropout[clientId] == CODEFINISHER ]\n",
    "\n",
    "NBROFSELECTED = 4\n",
    "firstFourClientMails = { thisId:selectFirstNMailTextsFrom(allMails[thisId],CLIENT,NBROFSELECTED) for thisId in allMails }\n",
    "firstFourClientMailsDropout = [ firstFourClientMails[clientId] for clientId in dropout if dropout[clientId] == CODEDROPOUT ]\n",
    "firstFourClientMailsFinisher = [ firstFourClientMails[clientId] for clientId in dropout if dropout[clientId] == CODEFINISHER ]\n",
    "\n",
    "CUTOFF = 1000\n",
    "NBROFSELECTED = 4\n",
    "firstFourClientMailsCutoff = { thisId:selectFirstNMailTextsFrom(allMails[thisId],CLIENT,NBROFSELECTED,cutoff=CUTOFF) for thisId in allMails }\n",
    "firstFourClientMailsCutoffDropout = [ firstFourClientMailsCutoff[clientId] for clientId in dropout if dropout[clientId] == CODEDROPOUT ]\n",
    "firstFourClientMailsCutoffFinisher = [ firstFourClientMailsCutoff[clientId] for clientId in dropout if dropout[clientId] == CODEFINISHER ]\n",
    "\n",
    "allMailsClientsDropout = [ selectAllMailTextFrom(allMails[clientId],CLIENT) for clientId in allMails if dropout[clientId] == CODEDROPOUT ]\n",
    "allMailsClientsFinisher = [ selectAllMailTextFrom(allMails[clientId],CLIENT) for clientId in allMails if dropout[clientId] == CODEFINISHER ]\n",
    "\n",
    "len(removeEmptyMails(allMailsClients)),len(removeEmptyMails(allMailsCounselors)),\\\n",
    "len(removeEmptyMails(lastCounselorMailsDropout)),len(removeEmptyMails(lastCounselorMailsFinisher)),\\\n",
    "len(removeEmptyMails(firstFourClientMailsDropout)),len(removeEmptyMails(firstFourClientMailsFinisher)),\\\n",
    "len(removeEmptyMails(firstFourClientMailsCutoffDropout)),len(removeEmptyMails(firstFourClientMailsCutoffFinisher)), \\\n",
    "len(removeEmptyMails(allMailsClientsDropout)),len(removeEmptyMails(allMailsClientsFinisher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference in the number of dropout sessions with counselor mails (437) and the number of dropout sessions with client mails (433). The reason for this is that there are four clients which contributed only a single empty mail to the session.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thisId in allMails:\n",
    "    mailText = selectAllMailTextFrom(allMails[thisId],CLIENT)\n",
    "    if (dropout[thisId] == \"1\" or dropout[thisId] == \"2\") and len(mailText) == 0: print(thisId,dropout[thisId])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have selected different groups of text, we can use the t-score for comparing the word usage in our group with another. Note that the comparison results will be better for larger word groups. In general it does not makes sense to compare two small groups of texts because neither of the two will provide a good model of the language to compare the other with. In those cases it is better to compare a small text with a large text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all mail texts: dropouts vs finishers\n",
    "\n",
    "The two groups of all dropout mails and all finisher mails are large enough to compare with each other. However the results may not be very useful for two reasons. First, on average the finishers took part in the therapy for a longer time than the dropouts. So they participated more frequently in later assignments and the language used in these assignments will have an effect on the measurements. A second reasond reason for the results being less interesting is that we would like to detect likely dropouts as early as possible in the therapy, so we do not have the time to collect their responses during several weeks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFSHOW = 40\n",
    "\n",
    "print(\"counts:\",\"allMailsClientsDropout:\",sum([wordCount(text) for text in allMailsClientsDropout]), \\\n",
    "                \"tokens;\",len(removeEmptyMails(allMailsClientsDropout)),\"mails;\", \\\n",
    "                \"allMailsClientsFinisher:\",sum([wordCount(text) for text in allMailsClientsFinisher]), \\\n",
    "                \"tokens;\",len(removeEmptyMails(allMailsClientsFinisher)),\"mails\" )\n",
    "tscoreData1 = makeTscoreData(removeEmptyMails(allMailsClientsDropout))\n",
    "tscoreData2 = makeTscoreData(removeEmptyMails(allMailsClientsFinisher))\n",
    "compareTscoreData(tscoreData1,tscoreData2,tscoreData2,tscoreData1,NBROFSHOW,\\\n",
    "                  coloredWords=[\"relatie\",\"kinderen\",\"huisarts\",\"partner\",\"ex\",\"ouders\",\"vrienden\",\"contacten\",\"vriendin\",\\\n",
    "                                \"pols\",\"vinger\",\"actieplan\",\"nameting\",\"traject\",\"opdracht\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that the finishers completed a larger part of the therapy is indeed reflected in their word usage, in particular by the therapy words *pols*, *vinger*, *actieplan*, *nameting*, *traject* and *opdracht*. The word *Dank* is also interesting here (displaying gratitude for a successful therapy?) as well as the two food-related diminuitives (*etentje* and *pilsje*: ability to relativate?). *gedachten*, *denken* and *herken* show the ability to reflect but may be invoked by later assignments. *trek* is an old-fashioned words correlated with the age of the client. The comma (*,*) was more used in this group (longer sentences?) while the periode (*.*) was more used by the dropouts (shorter sentences?).\n",
    "\n",
    "Interestingly, dropouts use more numbers (*NUM*) in their mails and more frequently refer to themselves (*mijn* and *Mijn*). The word *IK* is less interesting: it is an unusual spelling of a common word. There are seven more of these (*HET*, *DAT*, *VAN*, *DE*, *MIJN*, *EN* and *IS*) but they could be caused by a few clients writing all caps. There are many references to people and relations: *relatie*, *kinderen*, *huisarts*, *partner*, *ex*, *ouders*, *vrienden*, *contacten* and *vriendin*). *huisarts* could be used because of medical problems or extreme drinking behavior. While the finishers did not use negative words frequently, the dropouts did: *nadelen*, *problemen* and *klachten*. Two other interesting related words are *werk* and *hobby*, and there are also the three behavior-related words *drink*, *gebruik* and *stoppen*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function `collocations()` can be used to lookup tokens in context in the mails. For example, we expected that the word *pols* was predominantly used in the context of the name of the Tactus treatment programme *Vinger aan de pols* rather than in the literal meaning (*wrist*). Searching forthe contexts of the token with the `collocations()` function confirmed this expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDEFINED = \"UNDEF\"\n",
    "NBROFTOKENSAFTER = 0\n",
    "NBROFTOKENSBEFORE = 3\n",
    "NBROFCOLLOCATIONS = 20\n",
    "\n",
    "def makeCollocation(tokens,i,nbrOfTokensBefore,nbrOfTokensAfter):\n",
    "    collocationList = [tokens[i]]\n",
    "    for j in range(i-1,i-nbrOfTokensBefore-1,-1):\n",
    "        if j >= 0: collocationList = [tokens[j]]+collocationList\n",
    "        else: collocationList = [UNDEFINED]+collocationList\n",
    "    for j in range(i+1,i+nbrOfTokensAfter+1):\n",
    "        if j < len(tokens): collocationList.append(tokens[j])\n",
    "        else: collocationList.append(UNDEFINED)\n",
    "    return(\" \".join(collocationList))\n",
    "            \n",
    "def addToCollocations(collocations,tokens,i,nbrOfTokensBefore,nbrOfTokensAfter):\n",
    "    collocation = makeCollocation(tokens,i,nbrOfTokensBefore,nbrOfTokensAfter)\n",
    "    if collocation in collocations: collocations[collocation] += 1\n",
    "    else: collocations[collocation] = 1\n",
    "        \n",
    "def collocations(texts,token,nbrOfTokensBefore=NBROFTOKENSBEFORE,nbrOfTokensAfter=NBROFTOKENSAFTER,nbrOfCollocations=NBROFCOLLOCATIONS):\n",
    "    collocations = {}\n",
    "    total = 0\n",
    "    for text in texts:\n",
    "        tokens = text.split()\n",
    "        for i in range(0,len(tokens)):\n",
    "            if tokens[i] == token:\n",
    "                total += 1\n",
    "                addToCollocations(collocations,tokens,i,nbrOfTokensBefore,nbrOfTokensAfter)\n",
    "    print(\"total:\",total)\n",
    "    for key,value in sorted(collocations.items(), key=lambda item: item[1],reverse=True)[0:nbrOfCollocations]:\n",
    "        print(value,key)\n",
    "        \n",
    "collocations(allMailsClientsFinisher,\"pols\",nbrOfCollocations=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the final counselor mails: dropouts vs finishers\n",
    "\n",
    "We would like to know if it is possible to predict the result of the therapy (dropout vs finisher) based on the text of the final mail sent by the counselor. By themselves these mails do contain a lot of text so we compare them with all the mails of the counselors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"counts:\",\"lastCounselorMailsDropout:\",sum([wordCount(text) for text in lastCounselorMailsDropout]),\\\n",
    "                \"tokens;\",len(removeEmptyMails(lastCounselorMailsDropout)),\"mails;\", \\\n",
    "                \"lastCounselorMailsFinisher:\",sum([wordCount(text) for text in lastCounselorMailsFinisher]),\\\n",
    "                \"tokens;\",len(removeEmptyMails(lastCounselorMailsFinisher)),\"mails\" )\n",
    "tscoreData1 = makeTscoreData(removeEmptyMails(lastCounselorMailsDropout))\n",
    "tscoreData2 = makeTscoreData(removeEmptyMails(lastCounselorMailsFinisher))\n",
    "tscoreData3 = makeTscoreData(removeEmptyMails(allMailsCounselors))\n",
    "compareTscoreData(tscoreData1,tscoreData3,tscoreData2,tscoreData3,NBROFSHOW,\n",
    "                  coloredWords=[\"invullen\",\"vragenlijst\",\"stuur\",\"vullen\",\"verzoek\",\"actief\",\"niet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top finisher words provide the most clues for group identification. We observe calls to action (*invullen*, *vragenlijst*, *stuur*, *vullen* and *verzoek*) and expressions of completion (*afgerond* and *bedankt*). Among the top dropout words we find a reference to the clients status: *actief* (in combination with *niet*). *stuur* also appears here, in the instruction to the client on how to return to the programme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocations(lastCounselorMailsFinisher,\"actief\",nbrOfTokensBefore=2,nbrOfTokensAfter=2,nbrOfCollocations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the first four client mails: dropouts vs finishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"counts:\",\"firstFourClientMailsDropout:\",sum([wordCount(text) for text in firstFourClientMailsDropout]),\\\n",
    "                \"tokens;\",len(removeEmptyMails(firstFourClientMailsDropout)),\"mails;\", \\\n",
    "                \"firstFourClientMailsFinisher:\",sum([wordCount(text) for text in firstFourClientMailsFinisher]),\\\n",
    "                \"tokens;\",len(removeEmptyMails(firstFourClientMailsFinisher)),\"mails\" )\n",
    "tscoreData1 = makeTscoreData(removeEmptyMails(firstFourClientMailsDropout))\n",
    "tscoreData2 = makeTscoreData(removeEmptyMails(firstFourClientMailsFinisher))\n",
    "tscoreData3 = makeTscoreData(removeEmptyMails(allMailsClients))\n",
    "compareTscoreData(tscoreData1,tscoreData3,tscoreData2,tscoreData3,NBROFSHOW,\n",
    "                  coloredWords=[\"jaren\",\"(\",\"vaak\",\"voordelen\",\"top\",\"werd\",\"vader\",\"In\",\\\n",
    "                                \"regelmatig\",\"contact\",\"Top\",\"altijd\",\"'s\",\"naam\",\":\",\\\n",
    "                                \"ben\",\"gebruik\",\"hoogte\",\"relatie\",\"eet\",\"partner\",\"Vraag\",\"heb\",\"interesses\",\\\n",
    "                                \"ongeveer\",\"ouders\",\"vrijetijdsbesteding\",\"beantwoorden\",\"problemen\",\"soms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the words (25 of 40) in the two top usage lists are the same, showing that the language usage in the early mails is different from that in the other mails. In particular this is true for some of the relation words that we found in the comparison between all dropout and finisher mails (*kinderen* and *vrienden*). Interestingly, the dropout list contains several first person singular verbs (*ben*, *gebruik*, *eet* and *heb*) not present in the finisher list with the exception of *drink*. The dropout list still contains more relative words (*relatie*, *partner* and *ouders*) than the finisher list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A direct comparison between the two text collections reveals similar patterns: first person singular verb words (*heb*, *ben*, *drink* and *gebruik*) and relation words (*vriendin* and *zoontje*) among the top dropout words. A new topic is prominent among the finsher words: illnesses and physical problems (*kanker*, *pijn*, *chemo*, *arthritis*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareTscoreData(tscoreData1,tscoreData2,tscoreData2,tscoreData1,NBROFSHOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the longest among the first four client mails: dropouts vs finishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"counts:\",\"firstFourClientMailsCutoffDropout:\",sum([wordCount(text) for text in firstFourClientMailsCutoffDropout]),\\\n",
    "                \"tokens;\",len(removeEmptyMails(firstFourClientMailsCutoffDropout)),\"mails;\", \\\n",
    "                \"firstFourClientMailsCutoffFinisher:\",sum([wordCount(text) for text in firstFourClientMailsCutoffFinisher]),\\\n",
    "                \"tokens;\",len(removeEmptyMails(firstFourClientMailsCutoffFinisher)),\"mails\" )\n",
    "tscoreData1 = makeTscoreData(removeEmptyMails(firstFourClientMailsCutoffDropout))\n",
    "tscoreData2 = makeTscoreData(removeEmptyMails(firstFourClientMailsCutoffFinisher))\n",
    "tscoreData3 = makeTscoreData(removeEmptyMails(allMailsClients))\n",
    "compareTscoreData(tscoreData1,tscoreData3,tscoreData2,tscoreData3,NBROFSHOW,coloredWords=[\\\n",
    "                 \"(\",\"was\",\".\",\"kon\",\"contacten\",\"kreeg\",\"depressie\",\",\",\"geleden\",\"vader\",\"broer\",\"ad\",\"familie\",\"per\",\"ORG\",\"sinds\",\\\n",
    "                 \"kinderen\",\"“\",\"s\",\"Vraag\",\"drink\",\"eet\",\"”\",\"soms\",\"ben\",\"dagelijks\",\"…\",\"hobby\",\"maanden\",\"ongeveer\",\"baan\",\"weinig\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we examine only the longest (>= 1000 tokens) among the first four client mails, we see similar patterns: among the top dropout words several firts person singular verbs (*drink*, *eet* and *ben*) but person relation words (*kinderen* and *vader*) are now more present among the top finisher words (*contacten*, *vader*, *broer* and *familie*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing LIWC data\n",
    "\n",
    "We have compared word usage in the mail texts with the t-score. Next we want to compare the frequencies of LIWC categories in the mail texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTALTOKENS = \"Number of matches\"\n",
    "NBROFNBRS = \"number count\"\n",
    "EMPTYLIWCDICT = { TOTALTOKENS:0, NBROFNBRS:0 }\n",
    "\n",
    "def isLiwcFeature(featureName):\n",
    "    return(re.search(r\"^[0-9]\",str(featureName)))\n",
    "\n",
    "def combineLiwcResults(mails):\n",
    "    if len(mails) == 0: return(emptyResults)\n",
    "    else:\n",
    "        liwcResults = dict(EMPTYLIWCDICT)\n",
    "        for i in range(0,len(mails)):\n",
    "            liwcResults[TOTALTOKENS] += mails[i][TOTALTOKENS]\n",
    "            liwcResults[NBROFNBRS] += mails[i][NBROFNBRS]*mails[i][TOTALTOKENS]\n",
    "            for liwcField in mails[0].domain.variables:\n",
    "                if isLiwcFeature(liwcField):\n",
    "                    if not liwcField in liwcResults: \n",
    "                        liwcResults[liwcField] = mails[i][liwcField]*mails[i][TOTALTOKENS]\n",
    "                    else:\n",
    "                        liwcResults[liwcField] += mails[i][liwcField]*mails[i][TOTALTOKENS]\n",
    "        return(liwcResults)\n",
    "    \n",
    "def extractLiwcScoresFrom(liwcResultsIn,sender):\n",
    "    liwcResultsOut = {}\n",
    "    for clientId in liwcResultsIn:\n",
    "        mails = []\n",
    "        for mail in liwcResultsIn[clientId]:\n",
    "            if mail[FIELDNAMEFROM] == sender: mails.append(mail)\n",
    "        liwcResultsOut[clientId] = combineLiwcResults(mails)\n",
    "    return(liwcResultsOut)\n",
    "\n",
    "def combineLiwcScores(liwcResultsIn):\n",
    "    liwcResultsOut = dict(EMPTYLIWCDICT)\n",
    "    for clientId in liwcResultsIn:\n",
    "        liwcResultsOut[TOTALTOKENS] += liwcResultsIn[clientId][TOTALTOKENS]\n",
    "        liwcResultsOut[NBROFNBRS] += liwcResultsIn[clientId][NBROFNBRS]\n",
    "        for liwcField in liwcResultsIn[clientId].keys():\n",
    "            if str(liwcField) in liwcResultsOut:\n",
    "                liwcResultsOut[str(liwcField)] += liwcResultsIn[clientId][liwcField]\n",
    "            else:\n",
    "                liwcResultsOut[str(liwcField)] = liwcResultsIn[clientId][liwcField]\n",
    "    return(liwcResultsOut)\n",
    "\n",
    "def makeTscoreDataLiwc(liwcScores):\n",
    "    tScoreData = { NBROFTOKENS:int(liwcScores[TOTALTOKENS]), NBROFTYPES:int(len(liwcScores)-2), NBROFGROUPS:int(len(liwcScores)-2), WORDFREQS:{} }\n",
    "    for liwcField in liwcScores.keys():\n",
    "        if isLiwcFeature(liwcField):\n",
    "            tScoreData[WORDFREQS][liwcField] = int(liwcScores[liwcField])\n",
    "    return(tScoreData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all LIWC data: dropouts vs finishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwcScoresClientDropout = combineLiwcScores(extractLiwcScoresFrom({clientId:allLiwcResults[clientId] for clientId in allLiwcResults if dropout[clientId] == CODEDROPOUT},CLIENT))\n",
    "liwcScoresClientFinisher = combineLiwcScores(extractLiwcScoresFrom({clientId:allLiwcResults[clientId] for clientId in allLiwcResults if dropout[clientId] == CODEFINISHER},CLIENT))\n",
    "liwcTscoresClientDropout = makeTscoreDataLiwc(liwcScoresClientDropout)\n",
    "liwcTscoresClientFinisher = makeTscoreDataLiwc(liwcScoresClientFinisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFSHOWLIWC = 37\n",
    "print(\"counts:\",\"liwcTscoresClientDropout:\",liwcTscoresClientDropout[NBROFTOKENS],\\\n",
    "                \"tokens;\",\n",
    "                \"liwcTscoresClientFinisher:\",liwcTscoresClientFinisher[NBROFTOKENS],\\\n",
    "                \"tokens;\")\n",
    "compareTscoreData(liwcTscoresClientDropout,liwcTscoresClientFinisher,liwcTscoresClientFinisher,liwcTscoresClientDropout,NBROFSHOWLIWC,\\\n",
    "                 coloredWords=[\"41 family\",\"42 friend\",\"40 social\",\"4 i\",\"43 female\",\"44 male\",\"7 shehe\",\"8 they\",\"5 we\",\"6 you\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing LIWC data of the final counselor mails: dropouts vs finishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastLiwcScoresFrom(liwcResultsIn,sender):\n",
    "    liwcResultsOut = {}\n",
    "    for clientId in liwcResultsIn:\n",
    "        for i in range(0,len(liwcResultsIn)):\n",
    "            if liwcResultsIn[clientId][-1-i][FIELDNAMEFROM] == sender:\n",
    "                liwcResultsOut[clientId] = combineLiwcResults([liwcResultsIn[clientId][-1-i]])\n",
    "                break\n",
    "    return(liwcResultsOut)\n",
    "\n",
    "liwcScoresCounselorDropout = combineLiwcScores(\\\n",
    "                             getLastLiwcScoresFrom({clientId:allLiwcResults[clientId] for clientId in allLiwcResults if dropout[clientId] == CODEDROPOUT},COUNSELOR))\n",
    "liwcScoresCounselorFinisher = combineLiwcScores(\\\n",
    "                              getLastLiwcScoresFrom({clientId:allLiwcResults[clientId] for clientId in allLiwcResults if dropout[clientId] == CODEFINISHER},COUNSELOR))\n",
    "liwcScoresCounselor = combineLiwcScores(extractLiwcScoresFrom(allLiwcResults,COUNSELOR))\n",
    "liwcTscoresCounselorDropout = makeTscoreDataLiwc(liwcScoresCounselorDropout)\n",
    "liwcTscoresCounselorFinisher = makeTscoreDataLiwc(liwcScoresCounselorFinisher)\n",
    "liwcTscoresCounselor = makeTscoreDataLiwc(liwcScoresCounselor)\n",
    "\n",
    "NBROFSHOWLIWC = 37\n",
    "print(\"counts:\",\"liwcTscoresClientDropout:\",liwcTscoresCounselorDropout[NBROFTOKENS],\\\n",
    "                \"tokens;\",\n",
    "                \"liwcTscoresClientFinisher:\",liwcTscoresCounselorFinisher[NBROFTOKENS],\\\n",
    "                \"tokens;\")\n",
    "compareTscoreData(liwcTscoresCounselorDropout,liwcTscoresCounselor,liwcTscoresCounselorFinisher,liwcTscoresCounselor,NBROFSHOW,\\\n",
    "                  coloredWords=[\"40 social\",\"102 space\",\"81 affiliation\",\"62 hear\",\"15 negate\",\"56 differ\",\"42 friend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP = \"@\"\n",
    "\n",
    "tokenCounts = {}\n",
    "searchKey = \"social\"\n",
    "\n",
    "for token in {clientId:allLiwcResults[clientId] for clientId in allLiwcResults if dropout[clientId] == CODEDROPOUT}[\"AdB0001\"][-1].metas[2].split():\n",
    "    keys = token.split(SEP)\n",
    "    for key in keys[1:]:\n",
    "        if key == searchKey:\n",
    "            if key[0] in tokenCounts: tokenCounts[keys[0]] += 1\n",
    "            else: tokenCounts[keys[0]] = 1\n",
    "print(tokenCounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: male vs female words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "sys.path.append('/home/erikt/projects/e-mental-health/data-processing')\n",
    "import tactus2table\n",
    "\n",
    "DIRECTORY = \"/home/erikt/projects/e-mental-health/usb/tmp/20190917/\"\n",
    "FILENAMEPREFIX = \"^AdB\"\n",
    "TITLE = \"0-title\"\n",
    "FIELDNAMEINTAKE = \"Intake\"\n",
    "FIELDNAMEID = \"0-id\"\n",
    "FIELDNAMEGENDER = \"geslacht\"\n",
    "GZEXTENSION = \".gz\"\n",
    "XMLEXTENSION = \".xml\"\n",
    "MALE = \"man\"\n",
    "FEMALE = \"vrouw\"\n",
    "INTAKE = \"Intake\"\n",
    "\n",
    "def shortenFileName(fileName):\n",
    "    return(re.sub(XMLEXTENSION,\"\",re.sub(GZEXTENSION,\"\",fileName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = {}\n",
    "for inFileName in os.listdir(DIRECTORY):\n",
    "    if re.search(FILENAMEPREFIX,inFileName):\n",
    "        root = tactus2table.readRootFromFile(DIRECTORY+\"/\"+inFileName)\n",
    "        questionnaires = tactus2table.getQuestionnaires(root,inFileName)\n",
    "        for questionnaire in questionnaires: \n",
    "            if questionnaire[TITLE] == INTAKE:\n",
    "                for fieldName in questionnaire:\n",
    "                    if re.search(FIELDNAMEGENDER,fieldName):\n",
    "                        genders[shortenFileName(questionnaire[FIELDNAMEID])] = questionnaire[fieldName].lower()\n",
    "                        break\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderKeys = list(np.unique(np.array([genders[key] for key in genders])))\n",
    "genderMailTexts = {}\n",
    "for key in genderKeys: genderMailTexts[key] = {}\n",
    "for result in range(0,len(mailTexts)):\n",
    "    for fileId in mailTexts[result].keys():\n",
    "        genderMailTexts[genders[fileId]][fileId] = mailTexts[result][fileId]\n",
    "[(key,len(genderMailTexts[key])) for key in genderKeys]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscoreData1 = makeTscoreData(uniqueTextArray(genderMailTexts[MALE]))\n",
    "tscoreData2 = makeTscoreData(uniqueTextArray(genderMailTexts[FEMALE]))\n",
    "computeTscores(tscoreData1,tscoreData2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get treatment years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDNAMEDATE = \"date\"\n",
    "\n",
    "endYears = []\n",
    "startYears = []\n",
    "treatmentYearList = {}\n",
    "for clientId in allMails:\n",
    "    startYear = str(allMails[clientId][0][FIELDNAMEDATE])[0:4]\n",
    "    endYear = str(allMails[clientId][-1][FIELDNAMEDATE])[0:4]\n",
    "    startYears.append(int(startYear))\n",
    "    endYears.append(int(endYear))\n",
    "    treatmentYears = startYear+\"-\"+endYear\n",
    "    if treatmentYears in treatmentYearList: treatmentYearList[treatmentYears] += 1\n",
    "    else: treatmentYearList[treatmentYears] = 1\n",
    "\n",
    "years = {}\n",
    "for i in range(0,len(startYears)):\n",
    "    for year in range(startYears[i],endYears[i]+1):\n",
    "        if year in years: years[year] += 1\n",
    "        else: years[year] = 1\n",
    "for year in sorted(years.keys()):\n",
    "    print(years[year],year)\n",
    "    \n",
    "sum(years.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count mails of dropouts and completers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "CODECOMPLETER = \"2\"\n",
    "\n",
    "def std(data,avg):\n",
    "    total = 0\n",
    "    for i in range(0,len(data)): total += (data[i]-avg)**2\n",
    "    return(math.sqrt(total/len(data)))\n",
    "\n",
    "nbrOfClientMailsDropouts = []\n",
    "nbrOfClientMailsCompleters = []\n",
    "for clientId in allMails:\n",
    "    clientMailCounter = 0\n",
    "    for i in range(0,len(allMails[clientId])):\n",
    "        if allMails[clientId][i][FIELDNAMEFROM] == CLIENT: clientMailCounter += 1\n",
    "    if dropout[clientId] == CODEDROPOUT: nbrOfClientMailsDropouts.append(clientMailCounter)\n",
    "    if dropout[clientId] == CODECOMPLETER: nbrOfClientMailsCompleters.append(clientMailCounter)\n",
    "        \n",
    "print(\"dropouts: \",\"average:\",round(np.mean(nbrOfClientMailsDropouts),1),\"+-\",round(np.std(nbrOfClientMailsDropouts),1),\\\n",
    "                   \"  median:\",round(np.median(nbrOfClientMailsDropouts),1),\"+-\",round(std(nbrOfClientMailsDropouts,np.median(nbrOfClientMailsDropouts)),1))\n",
    "print(\"finishers:\",\"average:\",round(np.mean(nbrOfClientMailsCompleters),1),\"+-\",round(np.std(nbrOfClientMailsCompleters),1),\\\n",
    "                   \"median:\",round(np.median(nbrOfClientMailsCompleters),1),\"+-\",round(std(nbrOfClientMailsCompleters,np.median(nbrOfClientMailsCompleters)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in nbrOfClientMailsDropouts: print(d,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in nbrOfClientMailsFinishers: print(f,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nbrOfClientMailsDropouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-orange",
   "language": "python",
   "name": "python-orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
